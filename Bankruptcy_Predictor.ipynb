{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78f8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7    Attr8  \\\n",
      "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
      "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
      "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
      "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
      "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
      "\n",
      "    Attr9   Attr10  ...    Attr56   Attr57   Attr58    Attr59  Attr60  Attr61  \\\n",
      "0  1.1389  0.50494  ...  0.121960  0.39718  0.87804  0.001924  8.4160  5.1372   \n",
      "1  1.6996  0.49788  ...  0.121300  0.42002  0.85300  0.000000  4.1486  3.2732   \n",
      "2  1.3090  0.30408  ...  0.241140  0.81774  0.76599  0.694840  4.9909  3.9510   \n",
      "3  1.0571  0.57353  ...  0.054015  0.14207  0.94598  0.000000  4.5746  3.6147   \n",
      "4  1.1559  0.38677  ...  0.134850  0.48431  0.86515  0.124440  6.3985  4.3158   \n",
      "\n",
      "    Attr62  Attr63   Attr64  class  \n",
      "0   82.658  4.4158   7.4277      0  \n",
      "1  107.350  3.4000  60.9870      0  \n",
      "2  134.270  2.7185   5.2078      0  \n",
      "3   86.435  4.2228   5.5497      0  \n",
      "4  127.210  2.8692   7.8980      0  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_preprocess_data(file_path):\n",
    "    data, meta = arff.loadarff(file_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convert byte string to normal string for object-type columns\n",
    "    str_df = df.select_dtypes([np.object])\n",
    "    str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "    \n",
    "    for col in str_df:\n",
    "        df[col] = str_df[col]\n",
    "    \n",
    "    # Handle missing values\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    \n",
    "    # Convert all columns to numeric\n",
    "    df = df.apply(pd.to_numeric)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load and preprocess each file\n",
    "file_paths = ['1year.arff', '2year.arff', '3year.arff', '4year.arff', '5year.arff']\n",
    "all_data = pd.concat([load_preprocess_data(f'{file}') for file in file_paths])\n",
    "\n",
    "# Display first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f67192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last column is the target variable\n",
    "X = all_data.iloc[:, :-1]  # Features\n",
    "y = all_data.iloc[:, -1]   # Target\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de305fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,273\n",
      "Trainable params: 6,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 04:16:33.655197: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2023-11-30 04:16:33.676010: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3691525000 Hz\n",
      "2023-11-30 04:16:33.676578: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1af5580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-30 04:16:33.676601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-30 04:16:33.676725: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Building a Neural Network for Bankruptcy Prediction\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27779 samples, validate on 6945 samples\n",
      "Epoch 1/100\n",
      "27779/27779 [==============================] - 5s 189us/sample - loss: 0.2352 - accuracy: 0.9523 - val_loss: 0.1945 - val_accuracy: 0.9497\n",
      "Epoch 2/100\n",
      "27779/27779 [==============================] - 4s 144us/sample - loss: 0.1940 - accuracy: 0.9530 - val_loss: 0.1884 - val_accuracy: 0.9499\n",
      "Epoch 3/100\n",
      "27779/27779 [==============================] - 4s 151us/sample - loss: 0.1889 - accuracy: 0.9530 - val_loss: 0.1880 - val_accuracy: 0.9497\n",
      "Epoch 4/100\n",
      "27779/27779 [==============================] - 5s 162us/sample - loss: 0.1860 - accuracy: 0.9530 - val_loss: 0.1878 - val_accuracy: 0.9496\n",
      "Epoch 5/100\n",
      "27779/27779 [==============================] - 4s 139us/sample - loss: 0.1807 - accuracy: 0.9532 - val_loss: 0.1853 - val_accuracy: 0.9496\n",
      "Epoch 6/100\n",
      "27779/27779 [==============================] - 4s 155us/sample - loss: 0.1784 - accuracy: 0.9533 - val_loss: 0.1845 - val_accuracy: 0.9496\n",
      "Epoch 7/100\n",
      "27779/27779 [==============================] - 4s 158us/sample - loss: 0.1777 - accuracy: 0.9533 - val_loss: 0.1838 - val_accuracy: 0.9496\n",
      "Epoch 8/100\n",
      "27779/27779 [==============================] - 4s 157us/sample - loss: 0.1796 - accuracy: 0.9532 - val_loss: 0.1868 - val_accuracy: 0.9496\n",
      "Epoch 9/100\n",
      "27779/27779 [==============================] - 4s 157us/sample - loss: 0.1743 - accuracy: 0.9531 - val_loss: 0.1848 - val_accuracy: 0.9497\n",
      "Epoch 10/100\n",
      "27779/27779 [==============================] - 4s 133us/sample - loss: 0.1746 - accuracy: 0.9531 - val_loss: 0.1848 - val_accuracy: 0.9497\n",
      "Epoch 11/100\n",
      "27779/27779 [==============================] - 4s 138us/sample - loss: 0.1726 - accuracy: 0.9533 - val_loss: 0.1822 - val_accuracy: 0.9497\n",
      "Epoch 12/100\n",
      "27779/27779 [==============================] - 4s 150us/sample - loss: 0.1715 - accuracy: 0.9532 - val_loss: 0.1812 - val_accuracy: 0.9497\n",
      "Epoch 13/100\n",
      "27779/27779 [==============================] - 4s 161us/sample - loss: 0.1723 - accuracy: 0.9531 - val_loss: 0.1820 - val_accuracy: 0.9497\n",
      "Epoch 14/100\n",
      "27779/27779 [==============================] - 5s 163us/sample - loss: 0.1700 - accuracy: 0.9532 - val_loss: 0.1817 - val_accuracy: 0.9497\n",
      "Epoch 15/100\n",
      "27779/27779 [==============================] - 4s 141us/sample - loss: 0.1704 - accuracy: 0.9532 - val_loss: 0.1812 - val_accuracy: 0.9497\n",
      "Epoch 16/100\n",
      "27779/27779 [==============================] - 4s 142us/sample - loss: 0.1702 - accuracy: 0.9532 - val_loss: 0.1803 - val_accuracy: 0.9496\n",
      "Epoch 17/100\n",
      "27779/27779 [==============================] - 4s 158us/sample - loss: 0.1692 - accuracy: 0.9532 - val_loss: 0.1801 - val_accuracy: 0.9497\n",
      "Epoch 18/100\n",
      "27779/27779 [==============================] - 4s 146us/sample - loss: 0.1695 - accuracy: 0.9532 - val_loss: 0.1807 - val_accuracy: 0.9496\n",
      "Epoch 19/100\n",
      "27779/27779 [==============================] - 4s 158us/sample - loss: 0.1691 - accuracy: 0.9530 - val_loss: 0.1802 - val_accuracy: 0.9497\n",
      "Epoch 20/100\n",
      "27779/27779 [==============================] - 4s 146us/sample - loss: 0.1668 - accuracy: 0.9533 - val_loss: 0.1820 - val_accuracy: 0.9497\n",
      "Epoch 21/100\n",
      "27779/27779 [==============================] - 4s 152us/sample - loss: 0.1694 - accuracy: 0.9531 - val_loss: 0.1795 - val_accuracy: 0.9497\n",
      "Epoch 22/100\n",
      "27779/27779 [==============================] - 4s 145us/sample - loss: 0.1675 - accuracy: 0.9531 - val_loss: 0.1795 - val_accuracy: 0.9497\n",
      "Epoch 23/100\n",
      "27779/27779 [==============================] - 4s 145us/sample - loss: 0.1669 - accuracy: 0.9532 - val_loss: 0.1795 - val_accuracy: 0.9497\n",
      "Epoch 24/100\n",
      "27779/27779 [==============================] - 4s 157us/sample - loss: 0.1669 - accuracy: 0.9533 - val_loss: 0.1815 - val_accuracy: 0.9497\n",
      "Epoch 25/100\n",
      "27779/27779 [==============================] - 4s 146us/sample - loss: 0.1672 - accuracy: 0.9532 - val_loss: 0.1786 - val_accuracy: 0.9497\n",
      "Epoch 26/100\n",
      "27779/27779 [==============================] - 4s 145us/sample - loss: 0.1654 - accuracy: 0.9533 - val_loss: 0.1778 - val_accuracy: 0.9499\n",
      "Epoch 27/100\n",
      "27779/27779 [==============================] - 4s 138us/sample - loss: 0.1657 - accuracy: 0.9534 - val_loss: 0.1791 - val_accuracy: 0.9497\n",
      "Epoch 28/100\n",
      "27779/27779 [==============================] - 4s 146us/sample - loss: 0.1642 - accuracy: 0.9532 - val_loss: 0.1824 - val_accuracy: 0.9497\n",
      "Epoch 29/100\n",
      "27779/27779 [==============================] - 4s 149us/sample - loss: 0.1635 - accuracy: 0.9533 - val_loss: 0.1791 - val_accuracy: 0.9497\n",
      "Epoch 30/100\n",
      "27779/27779 [==============================] - 4s 160us/sample - loss: 0.1628 - accuracy: 0.9533 - val_loss: 0.1796 - val_accuracy: 0.9497\n",
      "Epoch 31/100\n",
      "27779/27779 [==============================] - 4s 153us/sample - loss: 0.1647 - accuracy: 0.9531 - val_loss: 0.1783 - val_accuracy: 0.9496\n",
      "Epoch 32/100\n",
      "27779/27779 [==============================] - 4s 139us/sample - loss: 0.1643 - accuracy: 0.9532 - val_loss: 0.1783 - val_accuracy: 0.9497\n",
      "Epoch 33/100\n",
      "27779/27779 [==============================] - 5s 164us/sample - loss: 0.1637 - accuracy: 0.9532 - val_loss: 0.1794 - val_accuracy: 0.9497\n",
      "Epoch 34/100\n",
      "27779/27779 [==============================] - 4s 152us/sample - loss: 0.1642 - accuracy: 0.9532 - val_loss: 0.1801 - val_accuracy: 0.9497\n",
      "Epoch 35/100\n",
      "27779/27779 [==============================] - 5s 183us/sample - loss: 0.1631 - accuracy: 0.9532 - val_loss: 0.1785 - val_accuracy: 0.9497\n",
      "Epoch 36/100\n",
      "27779/27779 [==============================] - 4s 152us/sample - loss: 0.1630 - accuracy: 0.9532 - val_loss: 0.1791 - val_accuracy: 0.9497\n",
      "Epoch 37/100\n",
      "27456/27779 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9531"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.3f}, Test Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Plotting training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8031ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
